{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Detecting the fiducial particles in LM images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fiducial particles appear as bright spots in the LM images. In this notebook, we **detect fiducial particles** in **LM images** using Big-FISH - a python package originally created for analysis of smFISH images. It includes various methods, such as spot detection which we are using in this notebook. The main steps of this algorithm then are:\n",
    "- **1. Spot detection** - Detection of fiducial particles using spot detection methods from Big-FISH package\n",
    "- **2. Dense region decomposition** - Recognizing larger and brighter (dense) spots as clusters and estimating the number of individual fiducial particles building these clusters\n",
    "- **3. Save results** - Saving the positions of all detected fiducial particles and the positions of fiducial clusters into files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the necessary python libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T16:01:29.143710Z",
     "start_time": "2022-09-05T16:01:27.173886Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import plot_image, list_to_dataframe, dataframe_to_xml_, dataframe_to_pointcloud\n",
    "import open3d as o3d\n",
    "from probreg import cpd\n",
    "from pathlib import Path\n",
    "import bigfish\n",
    "import bigfish.stack as stack\n",
    "import bigfish.detection as detection\n",
    "import bigfish.multistack as multistack\n",
    "import bigfish.plot as plot\n",
    "print(\"Big-FISH version: {0}\".format(bigfish.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the path to the input EM and LM images and load them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T16:01:29.258259Z",
     "start_time": "2022-09-05T16:01:29.242094Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "input_folder = 'E:/DATA/AI4Life_Pr26/20240805_Trial_data_fiducial_particles/240723_JB294_CLEM-AI4life_sample1/pos1'\n",
    "test_folder = '//vironova.com/root/Users/kristinal/Documents/1Test'\n",
    "\n",
    "EM_image_path = os.path.join(input_folder, \"240726_JB295_HEK293_CLEM_LAMP1-488_Particles-555_grid4_pos1_bin4_EM.tif\")\n",
    "LM_image_path = os.path.join(input_folder, \"C2-experiment_ai4life.tif\")\n",
    "\n",
    "print(Path(EM_image_path).exists())\n",
    "print(Path(LM_image_path).exists())\n",
    "\n",
    "output_folder = Path(os.path.join(input_folder,\"output\"))\n",
    "output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "EMimage = stack.read_image(EM_image_path)\n",
    "LMimage = stack.read_image(LM_image_path)\n",
    "\n",
    "print(\"EMimage\")\n",
    "print(\"\\r shape: {0}\".format(EMimage.shape))\n",
    "print(\"\\r dtype: {0}\".format(EMimage.dtype))\n",
    "\n",
    "print(\"LMimage:\")\n",
    "print(\"\\r shape: {0}\".format(LMimage.shape))\n",
    "print(\"\\r dtype: {0}\".format(LMimage.dtype))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the size of the bigger EM image and rescale the LM image accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_LMimage = stack.resize_image(LMimage, EMimage.shape, method='bilinear')\n",
    "\n",
    "print(\"resized_LMimage:\")\n",
    "print(\"\\r shape: {0}\".format(resized_LMimage.shape))\n",
    "print(\"\\r dtype: {0}\".format(resized_LMimage.dtype))\n",
    "\n",
    "scale_x = EMimage.shape[0]/LMimage.shape[0]\n",
    "scale_y = EMimage.shape[1]/LMimage.shape[1]\n",
    "\n",
    "print(scale_x)\n",
    "print(scale_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#overlaid_image = stack.maximum_projection(np.stack([resized_LMimage, EMimage]))\n",
    "#plot.plot_images(overlaid_image, contrast=True, framesize=(5, 5))\n",
    "\n",
    "fig = plt.figure(figsize=(40, 40))\n",
    "plt.imshow(resized_LMimage, cmap='gray', alpha=0.5)\n",
    "plt.imshow(EMimage, cmap='gray', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 1. Spot detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We assume **spot is a local maximum** in the LM image. Three steps are required to detect them:\n",
    "- Filter the LM image to enhance the signal-to-noise ratio and denoise the image (`bigfish.stack.log_filter`).\n",
    "- Detect the local maximum in the filtered image (`bigfish.detection.local_maximum_detection`).\n",
    "- Remove the local maximum under a fixed threshold (`bigfish.detection.spots_thresholding`). To be robust, the thresholding should be applied on the filtered image. Thus, the threshold is set relatively to the filtered image values.\n",
    "- If necessary, the optimal threshold can be estimated with `bigfish.detection.automated_threshold_setting` (applied on a filtered image).\n",
    "\n",
    "All these steps are summarized in `bigfish.detection.detect_spots` that return the 2D or 3D coordinates of the detected spots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T16:01:31.903304Z",
     "start_time": "2022-09-05T16:01:29.274904Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "vox_size = 110  # voxel size in nanometers\n",
    "spot_rad = 100 \n",
    "\n",
    "spots, threshold = detection.detect_spots(\n",
    "    images=LMimage, \n",
    "    return_threshold=True, \n",
    "    voxel_size=(vox_size, vox_size),  # in nanometer (one value per dimension zyx)\n",
    "    spot_radius=(spot_rad, spot_rad))  # in nanometer (one value per dimension zyx)\n",
    "\n",
    "# From Fiji file:\n",
    "# Width:  29.2602 microns (266)\n",
    "# Height:  71.2805 microns (648)\n",
    "# Size:  1010K\n",
    "# Resolution:  9.0908 pixels per micron\n",
    "# Voxel size: 0.1100x0.1100x1 micron^3\n",
    "\n",
    "print(\"detected spots\")\n",
    "print(\"\\r shape: {0}\".format(spots.shape))\n",
    "print(\"\\r dtype: {0}\".format(spots.dtype))\n",
    "print(\"\\r threshold: {0}\".format(threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Given the **voxel size** and the expected **spot radius** (in nanometer), the function `bigfish.detection.detect_spots` automatically estimates a **kernel size** for the LoG filtering and a **minimal distance** between two spots we want to be able to detect separately. It is still possible to set these parameters explicitly in order to fine-tune the detection. Internally, we approximate them as the spot radius in pixel with the function `bigfish.detection.get_object_radius_pixel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T16:01:31.909421Z",
     "start_time": "2022-09-05T16:01:31.905453Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "spot_radius_px = detection.get_object_radius_pixel(\n",
    "    voxel_size_nm=(vox_size, vox_size), \n",
    "    object_radius_nm=(spot_rad, spot_rad), \n",
    "    ndim=2)\n",
    "print(\"spot radius (z axis): {:0.3f} pixels\".format(spot_radius_px[0]))\n",
    "print(\"spot radius (yx plan): {:0.3f} pixels\".format(spot_radius_px[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T16:01:34.519181Z",
     "start_time": "2022-09-05T16:01:31.912403Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "spots, threshold = detection.detect_spots(\n",
    "    images=LMimage, \n",
    "    return_threshold=True, \n",
    "    log_kernel_size=(1.000, 1.000),\n",
    "    minimum_distance=(1.000, 1.000))\n",
    "print(\"detected spots\")\n",
    "print(\"\\r shape: {0}\".format(spots.shape))\n",
    "print(\"\\r dtype: {0}\".format(spots.dtype))\n",
    "print(\"\\r threshold: {0}\".format(threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "__Note:__ What we call spot radius in this notebook can be understood as its **Point Spread Function (PSF)**. For simplicity sake, this PSF is modelled as a 2D or 3D gaussian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The previous steps can be computed separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T16:01:35.746683Z",
     "start_time": "2022-09-05T16:01:34.521143Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# spot radius\n",
    "spot_radius_px = detection.get_object_radius_pixel(\n",
    "    voxel_size_nm=(vox_size, vox_size), \n",
    "    object_radius_nm=(spot_rad, spot_rad), \n",
    "    ndim=2)\n",
    "\n",
    "# LoG filter\n",
    "rna_log = stack.log_filter(LMimage, sigma=spot_radius_px)\n",
    "\n",
    "# local maximum detection\n",
    "mask = detection.local_maximum_detection(rna_log, min_distance=spot_radius_px)\n",
    "\n",
    "# thresholding\n",
    "threshold = detection.automated_threshold_setting(rna_log, mask)\n",
    "threshold = 1500\n",
    "spots, _ = detection.spots_thresholding(rna_log, mask, threshold)\n",
    "print(\"detected spots\")\n",
    "print(\"\\r shape: {0}\".format(spots.shape))\n",
    "print(\"\\r dtype: {0}\".format(spots.dtype))\n",
    "print(\"\\r threshold: {0}\".format(threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T16:01:38.786387Z",
     "start_time": "2022-09-05T16:01:35.749355Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "plot.plot_detection(LMimage, spots, contrast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The automated spot detection method tries to find the optimal threshold to discriminate actual spots from noisy blobs. If we plot the number of the spots detected as a function of threshold level we observe an **elbow curve**. The selected threshold is the one located in the breaking point of the curve. This curve can be plotted with `bigfish.plot.plot_elbow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T16:01:41.132115Z",
     "start_time": "2022-09-05T16:01:38.788085Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "plot.plot_elbow(\n",
    "    images=LMimage, \n",
    "    voxel_size=(vox_size, vox_size), \n",
    "    spot_radius=(spot_rad, spot_rad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 2. Dense region decomposition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The detection of local maximum is not able to detect individual fiducial particles clustered in a dense and bright region. We try to **decompose these regions by simulating as many spots as possible until we match the original region intensity**. Our current steps are:\n",
    "- Denoise the LM image by estimating then removing its background (`bigfish.stack.remove_background_gaussian`).\n",
    "- Build a reference median spot from the individual predetected spots (`bigfish.detection.build_reference_spot`).\n",
    "- Fit a gaussian signal on the reference spot (`bigfish.detection.modelize_spot`).\n",
    "- Detect the candidate dense regions in the denoised image - large regions brighter than the reference spot (`bigfish.detection.get_dense_region`).\n",
    "- Use the fitted gaussian signal to fill as many spots in the candidate regions as possible (`bigfish.detection.simulate_gaussian_mixture`).\n",
    "\n",
    "All these steps are summarized in `bigfish.detection.decompose_dense` that return the 2D or 3D coordinates of the detected spots outside and inside a decomposed region, additional information about the regions themself and an image of the reference spot estimated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T16:01:42.141254Z",
     "start_time": "2022-09-05T16:01:41.134544Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "spots_post_decomposition, dense_regions, reference_spot = detection.decompose_dense(\n",
    "    image=LMimage, \n",
    "    spots=spots, \n",
    "    voxel_size=(vox_size, vox_size), \n",
    "    spot_radius=(spot_rad, spot_rad), \n",
    "    alpha=0.3,  # alpha impacts the number of spots per candidate region\n",
    "    beta=1,  # beta impacts the number of candidate regions to decompose\n",
    "    gamma=5)  # gamma the filtering step to denoise the image\n",
    "print(\"detected spots before decomposition\")\n",
    "print(\"\\r shape: {0}\".format(spots.shape))\n",
    "print(\"\\r dtype: {0}\".format(spots.dtype), \"\\n\")\n",
    "print(\"detected spots after decomposition\")\n",
    "print(\"\\r shape: {0}\".format(spots_post_decomposition.shape))\n",
    "print(\"\\r dtype: {0}\".format(spots_post_decomposition.dtype))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Alternatively, all the previous steps can be computed separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T16:01:43.086020Z",
     "start_time": "2022-09-05T16:01:42.143530Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# gaussian kernel\n",
    "kernel_size = detection.get_object_radius_pixel(\n",
    "    voxel_size_nm=(vox_size, vox_size), \n",
    "    object_radius_nm=(spot_rad, spot_rad), \n",
    "    ndim=2)\n",
    "large_kernel_size = tuple([kernel_size_ * 5 for kernel_size_ in kernel_size])\n",
    "\n",
    "# denoising\n",
    "rna_denoised = stack.remove_background_gaussian(LMimage, sigma=large_kernel_size)\n",
    "\n",
    "# reference spot\n",
    "reference_spot = detection.build_reference_spot(\n",
    "    image=rna_denoised,\n",
    "    spots=spots,\n",
    "    voxel_size=(vox_size, vox_size), \n",
    "    spot_radius=(spot_rad, spot_rad),\n",
    "    alpha=0.7)\n",
    "\n",
    "# fit a gaussian function on the reference spot\n",
    "sigma_yx, amplitude, background = detection.modelize_spot(\n",
    "    reference_spot=reference_spot, \n",
    "    voxel_size=(vox_size, vox_size), \n",
    "    spot_radius=(spot_rad, spot_rad))\n",
    "\n",
    "# detect dense regions\n",
    "regions_to_decompose, spots_out_regions, region_size = detection.get_dense_region(\n",
    "    image=rna_denoised, \n",
    "    spots=spots,\n",
    "    voxel_size=(vox_size, vox_size),\n",
    "    spot_radius=(spot_rad, spot_rad),\n",
    "    beta=1)\n",
    "\n",
    "# precompute gaussian function values\n",
    "max_grid = max(200, region_size + 1)\n",
    "precomputed_gaussian = detection.precompute_erf(\n",
    "    ndim=2,\n",
    "    voxel_size=(vox_size, vox_size),\n",
    "    sigma=(sigma_yx, sigma_yx),\n",
    "    max_grid=max_grid)\n",
    "\n",
    "# simulate gaussian mixtures\n",
    "spots_in_regions, _ = detection.simulate_gaussian_mixture(\n",
    "    image=rna_denoised,\n",
    "    candidate_regions=regions_to_decompose,\n",
    "    voxel_size=(vox_size, vox_size),\n",
    "    sigma=(sigma_yx, sigma_yx),\n",
    "    amplitude=amplitude,\n",
    "    background=background,\n",
    "    precomputed_gaussian=precomputed_gaussian)\n",
    "\n",
    "spots_post_decomposition = np.concatenate((spots_out_regions, spots_in_regions[:, :2]), axis=0)\n",
    "print(\"detected spots before decomposition\")\n",
    "print(\"\\r shape: {0}\".format(spots.shape))\n",
    "print(\"\\r dtype: {0}\".format(spots.dtype), \"\\n\")\n",
    "print(\"detected spots after decomposition\")\n",
    "print(\"\\r shape: {0}\".format(spots_post_decomposition.shape))\n",
    "print(\"\\r dtype: {0}\".format(spots_post_decomposition.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T16:01:47.374203Z",
     "start_time": "2022-09-05T16:01:43.087698Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "plot.plot_detection(LMimage, spots_post_decomposition, contrast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(spots_post_decomposition)\n",
    "# Comverting list of tuples into nparray\n",
    "spots_inv = [[int(x*scale_y), int(y*scale_x)] for y, x in (spots_post_decomposition)]\n",
    "spots_inv = [[int(x), int(y)] for y, x in (spots_post_decomposition)]\n",
    "#loc = np.hstack((spots_inv, np.zeros((len(spots_inv), 1))))\n",
    "print(spots_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spots_post_decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all detected fiducial particles into a Pandas dataframe\n",
    "\n",
    "source_all_df = list_to_dataframe(spots_inv) #str(output_folder/\"source_all_df.csv\")\n",
    "\n",
    "# source = dataframe_to_nparray(source_all_df)\n",
    "dataframe_to_xml_(source_all_df,str(output_folder/\"source_all.xml\"))                      # str(output_folder/\"source.xml\")\n",
    "source_pcd = dataframe_to_pointcloud(source_all_df, str(output_folder/\"source_all.ply\"))  # \"str(output_folder/source.ply)\"\n",
    "\n",
    "print(source_all_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Clusters detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Two spots are considered connected if they localized within a specific radius (in nanometer). Above a minimum number of connected spots, a cluster can be defined. This detection can be computed with `bigfish.detection.detect_clusters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T16:01:47.529239Z",
     "start_time": "2022-09-05T16:01:47.519310Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "spots_post_clustering, clusters = detection.detect_clusters(\n",
    "    spots=np.asarray(spots_post_decomposition), \n",
    "    voxel_size=(110, 110), \n",
    "    radius=110, \n",
    "    nb_min_spots=3)\n",
    "print(\"detected spots after clustering\")\n",
    "print(\"\\r shape: {0}\".format(spots_post_clustering.shape))\n",
    "print(\"\\r dtype: {0}\".format(spots_post_clustering.dtype), \"\\n\")\n",
    "print(\"detected clusters\")\n",
    "print(\"\\r shape: {0}\".format(clusters.shape))\n",
    "print(\"\\r dtype: {0}\".format(clusters.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T16:01:51.901592Z",
     "start_time": "2022-09-05T16:01:47.531620Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# plot\n",
    "#plot.plot_detection(LMimage, spots_post_clustering, contrast=True)\n",
    "plot.plot_detection(LMimage, \n",
    "                    spots=[spots_post_decomposition, clusters[:, :2]], \n",
    "                    shape=[\"circle\", \"circle\"], \n",
    "                    radius=[3, 6], \n",
    "                    color=[\"red\", \"green\"],\n",
    "                    linewidth=[1, 2], \n",
    "                    fill=[False, False], \n",
    "                    contrast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Additional detection methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We crop a part of our smFISH channel to better visualize the results of the next methods. Especially, we look at a region without too many clustered spots because it could negativally impact **subpixel fitting** and **colocalized spots detection**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T16:01:51.977793Z",
     "start_time": "2022-09-05T16:01:51.902937Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# crop\n",
    "crop = LMimage[ 520:630, 150:260]\n",
    "crop_mip = LMimage[520:630, 150:260]\n",
    "print(\"smfish channel (crop)\")\n",
    "print(\"\\r shape: {0}\".format(crop.shape))\n",
    "print(\"\\r dtype: {0}\".format(crop.dtype), \"\\n\")\n",
    "\n",
    "# plot\n",
    "plot.plot_images(crop, contrast=True, framesize=(5, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Subpixel fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "If you analyze few isolated spots, it is possible to refine spots detections at the subpixel level with `bigfish.detection.fit_subpixel` (in 2D and 3D)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T16:01:52.905700Z",
     "start_time": "2022-09-05T16:01:51.982797Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# pixel fitting\n",
    "spots_crop = detection.detect_spots(\n",
    "    images=crop,\n",
    "    threshold=1500.0,  # previous threshold automatically find in the full image\n",
    "    voxel_size=(vox_size, vox_size),\n",
    "    spot_radius=(spot_rad, spot_rad))\n",
    "print(\"spots (pixel fitting)\")\n",
    "print(\"\\r shape: {0}\".format(spots_crop.shape))\n",
    "print(\"\\r dtype: {0}\".format(spots_crop.dtype), \"\\n\")\n",
    "\n",
    "# subpixel fitting\n",
    "spots_subpixel_crop = detection.fit_subpixel(\n",
    "    image=crop, \n",
    "    spots=spots_crop, \n",
    "    voxel_size=(vox_size, vox_size), \n",
    "    spot_radius=(spot_rad, spot_rad))\n",
    "print(\"spots (subpixel fitting)\")\n",
    "print(\"\\r shape: {0}\".format(spots_subpixel_crop.shape))\n",
    "print(\"\\r dtype: {0}\".format(spots_subpixel_crop.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T16:01:53.293352Z",
     "start_time": "2022-09-05T16:01:52.907690Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# plot\n",
    "plot.plot_detection(\n",
    "    crop_mip, \n",
    "    spots=[spots_crop, spots_subpixel_crop], \n",
    "    radius=2, \n",
    "    color=[\"red\", \"blue\"],\n",
    "    title=\"Red = pixel fitting | Blue = subpixel fitting\",\n",
    "    linewidth=2, contrast=True, framesize=(10, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Colocalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "To detect colocalized spots (over different channels), the function `bigfish.multistack.detect_spots_colocalization` is available. Here, as an example, we detect colocalized spots between the ones detected with a pixel accuracy and the ones with subpixel accuracy. Like the regular spot detection, if a threshold is not provided to discriminate colocalized spots from distant ones, the function tries to set one, automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T16:01:53.303255Z",
     "start_time": "2022-09-05T16:01:53.295760Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "(spots_1_colocalized, spots_2_colocalized, \n",
    " distances, \n",
    " indices_1, indices_2, \n",
    " threshold) = multistack.detect_spots_colocalization(\n",
    "    spots_1=spots_crop, \n",
    "    spots_2=spots_subpixel_crop,\n",
    "    voxel_size=(110,110),\n",
    "    return_indices=True,\n",
    "    return_threshold=True)\n",
    "print(\"colocalized spots\")\n",
    "print(\"\\r shape 1: {0}\".format(spots_1_colocalized.shape))\n",
    "print(\"\\r shape 2: {0}\".format(spots_2_colocalized.shape))\n",
    "print(\"\\r distances: {0}\".format(distances.shape))\n",
    "print(\"\\r indices 1: {0}\".format(indices_1.shape))\n",
    "print(\"\\r indices 2: {0}\".format(indices_2.shape))\n",
    "print(\"\\r threshold: {0:0.2f} nm\".format(threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T16:01:53.651418Z",
     "start_time": "2022-09-05T16:01:53.305606Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# plot\n",
    "plot.plot_detection(\n",
    "    crop_mip, \n",
    "    spots=[spots_1_colocalized, spots_2_colocalized], \n",
    "    radius=2, \n",
    "    color=[\"red\", \"blue\"],\n",
    "    title=\"Red = pixel fitting | Blue = subpixel fitting\",\n",
    "    linewidth=2, contrast=True, framesize=(10, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Using the same logic than `bigfish.plot.plot_elbow`, the automated colocalized spot detection method tries to find the optimal threshold to discriminate colocalized spots from distant ones. One can use `bigfish.plot.plot_elbow_colocalized` to visualize the impact of the threshold on the colocalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T16:01:53.846696Z",
     "start_time": "2022-09-05T16:01:53.653799Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "plot.plot_elbow_colocalized(\n",
    "    spots_1=spots_crop, \n",
    "    spots_2=spots_subpixel_crop, \n",
    "    voxel_size=(110,110))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Spots and foci coordinates can be saved in **npy files** (numpy dedicated format) or **csv files** using functions `bigfish.stack.save_array` and `bigfish.stack.save_data_to_csv` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T16:01:53.858659Z",
     "start_time": "2022-09-05T16:01:53.848372Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# save in npy files\n",
    "path = os.path.join(path_output, \"spots.npy\")\n",
    "stack.save_array(spots_post_clustering, path)\n",
    "path = os.path.join(path_output, \"clusters.npy\")\n",
    "stack.save_array(clusters, path)\n",
    "\n",
    "# save in csv files\n",
    "path = os.path.join(path_output, \"spots.csv\")\n",
    "stack.save_data_to_csv(spots_post_clustering, path)\n",
    "path = os.path.join(path_output, \"clusters.csv\")\n",
    "stack.save_data_to_csv(clusters, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Detection in 2D or 3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Based on the number of dimensions of the provided image, a 2D or 3D detection is performed and corresponding coordinates are returned. Parameters `voxel_size` and `spot_radius` should be adapted to the number of dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T16:01:53.996974Z",
     "start_time": "2022-09-05T16:01:53.860347Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "spots, threshold = detection.detect_spots(\n",
    "    images=LMimage, \n",
    "    return_threshold=True, \n",
    "    voxel_size=(103, 103),  # in nanometer (one value per dimension yx)\n",
    "    spot_radius=(150, 150))  # in nanometer (one value per dimension yx)\n",
    "print(\"detected spots\")\n",
    "print(\"\\r shape: {0}\".format(spots.shape))\n",
    "print(\"\\r dtype: {0}\".format(spots.dtype))\n",
    "print(\"\\r threshold: {0}\".format(threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T16:01:54.128259Z",
     "start_time": "2022-09-05T16:01:53.998715Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "spots_post_decomposition, dense_regions, reference_spot = detection.decompose_dense(\n",
    "    image=LMimage, \n",
    "    spots=spots, \n",
    "    voxel_size=(vox_size,vox_size), \n",
    "    spot_radius=(spot_rad,spot_rad), \n",
    "    alpha=0.3,  # alpha impacts the number of spots per candidate region\n",
    "    beta=1,  # beta impacts the number of candidate regions to decompose\n",
    "    gamma=5)  # gamma the filtering step to denoise the image\n",
    "print(\"detected spots before decomposition\")\n",
    "print(\"\\r shape: {0}\".format(spots.shape))\n",
    "print(\"\\r dtype: {0}\".format(spots.dtype), \"\\n\")\n",
    "print(\"detected spots after decomposition\")\n",
    "print(\"\\r shape: {0}\".format(spots_post_decomposition.shape))\n",
    "print(\"\\r dtype: {0}\".format(spots_post_decomposition.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T16:01:54.137697Z",
     "start_time": "2022-09-05T16:01:54.130098Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "spots_post_clustering, clusters = detection.detect_clusters(\n",
    "    spots=spots_post_decomposition, \n",
    "    voxel_size=(103, 103), \n",
    "    radius=350, \n",
    "    nb_min_spots=4)\n",
    "print(\"detected spots after clustering\")\n",
    "print(\"\\r shape: {0}\".format(spots_post_clustering.shape))\n",
    "print(\"\\r dtype: {0}\".format(spots_post_clustering.dtype), \"\\n\")\n",
    "print(\"detected clusters\")\n",
    "print(\"\\r shape: {0}\".format(clusters.shape))\n",
    "print(\"\\r dtype: {0}\".format(clusters.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T16:01:57.625249Z",
     "start_time": "2022-09-05T16:01:54.139869Z"
    },
    "deletable": false,
    "editable": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot\n",
    "plot.plot_detection(LMimage, \n",
    "                    spots=[spots_post_decomposition, clusters[:, :2]], \n",
    "                    shape=[\"circle\", \"square\"], \n",
    "                    radius=[3, 6], \n",
    "                    color=[\"red\", \"blue\"],\n",
    "                    linewidth=[1, 2], \n",
    "                    fill=[False, True], \n",
    "                    contrast=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI4Life_OC2_2024_26",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
