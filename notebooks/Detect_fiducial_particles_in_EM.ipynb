{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40e2ea0d",
   "metadata": {},
   "source": [
    "### Detect fiducial particles in EM image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfc93023",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils.object_detection import non_max_suppression\n",
    "from utils import list_to_dataframe, dataframe_to_nparray, dataframe_to_xml, dataframe_to_pointcloud\n",
    "\n",
    "\n",
    "def plot_image(image):    \n",
    "    \"\"\"\n",
    "    Plot a grayscale image in the original size - takes time\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(40, 40))\n",
    "    ax1 = plt.subplot(1, 1, 1) \n",
    "    ax1.imshow(image, cmap='gray')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c83a584",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Load the main image and template\n",
    "input_folder = Path('E:/DATA/AI4Life_Pr26/20240805_Trial_data_fiducial_particles/240723_JB294_CLEM-AI4life_sample1/pos1')\n",
    "input_file = '240726_JB295_HEK293_CLEM_LAMP1-488_Particles-555_grid4_pos1_bin4_EM_small.tif'\n",
    "image_path = input_folder / input_file\n",
    "\n",
    "output_folder = input_folder / 'output'\n",
    "output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "#image_path = Path('E:/DATA/AI4Life_Pr26/20240805_Trial_data_fiducial_particles/240723_JB294_CLEM-AI4life_sample1/pos1/240726_JB295_HEK293_CLEM_LAMP1-488_Particles-555_grid4_pos1_bin4_EM_small.tif')\n",
    "#image_path = Path('E:/DATA/AI4Life_Pr26/20240805_Trial_data_fiducial_particles/240723_JB294_CLEM-AI4life_sample1/pos2/240726_JB295_HEK293_CLEM_LAMP1-488_Particles-555_grid4_pos2_bin4_EM.tif')\n",
    "#image_path = Path('E:/DATA/AI4Life_Pr26/20240805_Trial_data_fiducial_particles/240723_JB294_CLEM-AI4life_sample1/pos3/240726_JB295_HEK293_CLEM_LAMP1-488_Particles-555_grid4_pos3_bin4_EM.tif')\n",
    "\n",
    "print(image_path.exists())\n",
    "\n",
    "#template_path = Path('E:/DATA/AI4Life_Pr26/20240805_Trial_data_fiducial_particles/240723_JB294_CLEM-AI4life_sample1/pos1/240726_JB295_HEK293_CLEM_LAMP1-488_Particles-555_grid4_pos1_bin4_EM_template.tif')\n",
    "#print(template_path.exists())\n",
    "\n",
    "image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "#template = cv2.imread(template_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Parameters\n",
    "matching_threshold = 0.7  # threshold for template matching\n",
    "overlap_threshold =0.1\n",
    "\n",
    "# Get template dimensions\n",
    "#h, w = template.shape\n",
    "\n",
    "# Information about fiducial particles\n",
    "fiducial_diam = 30     # diameter of fiducial particles in px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe27593",
   "metadata": {},
   "source": [
    "#### Creating the template\n",
    "\n",
    "Fiducial particles have a very distinct center, characterized by a dark dot surrounded by a gray region. Instead of attempting to match the entire particle using a full template, we focus on detecting the central region only. To accomplish this, the template can be easily generated artificially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1f35a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty template of size ('size','size') filled with constant value - 'value'\n",
    "size = 9  \n",
    "value = 80\n",
    "template = np.full((size, size), value, dtype=np.uint8)\n",
    "\n",
    "# Define the 3x3 pattern\n",
    "pattern = np.array([[4, 2, 4],\n",
    "                    [2, 0, 2],\n",
    "                    [4, 2, 4]])\n",
    "\n",
    "# Calculate the starting index to place the pattern in the middle of the template\n",
    "s_idx = (template.shape[0] - pattern.shape[0]) // 2\n",
    "e_idx = s_idx + pattern.shape[0]\n",
    "    \n",
    "# Place the pattern in the middle of the template\n",
    "template[s_idx:e_idx, s_idx:e_idx] = pattern\n",
    "\n",
    "#import bigfish.stack as stack\n",
    "#template = stack.resize_image(template,(template.shape[0]*2,template.shape[0]*2), method='bilinear')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f3d9e8",
   "metadata": {},
   "source": [
    "Sample 1 bin 2 is has higher resolution so it seams - so there is larger template needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "453c4401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty template of size ('size','size') filled with constant value - 'value'\n",
    "size = 11  \n",
    "value = 80\n",
    "template = np.full((size, size), value, dtype=np.uint8)\n",
    "\n",
    "# Define the 5x5 pattern\n",
    "pattern = np.array([[32, 8, 4, 8, 32],\n",
    "                    [8, 4, 2, 4, 8],\n",
    "                    [4, 2, 0, 2, 4],\n",
    "                    [8, 4, 2, 4, 8],\n",
    "                    [32, 8, 4, 8, 32]])\n",
    "\n",
    "# Calculate the starting index to place the pattern in the middle of the template\n",
    "s_idx = (template.shape[0] - pattern.shape[0]) // 2\n",
    "e_idx = s_idx + pattern.shape[0]\n",
    "    \n",
    "# Place the pattern in the middle of the template\n",
    "template[s_idx:e_idx, s_idx:e_idx] = pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4d94ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image(template)\n",
    "print(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5d628153",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Display the input image\n",
    "# plot_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bbce146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression(boxes, scores, threshold):\n",
    "    # Sort boxes by score in descending order\n",
    "    sorted_indices = np.argsort(scores)[::-1]\n",
    "    print(\"Indices: \", sorted_indices)\n",
    "    \n",
    "    keep_boxes = []\n",
    "    \n",
    "    while sorted_indices.size > 0:\n",
    "        # Pick the box with the highest score\n",
    "        box_id = sorted_indices[0]\n",
    "        keep_boxes.append(box_id)\n",
    "        \n",
    "        # Calculate IoU of the picked box with the rest\n",
    "        ious = calculate_iou(boxes[box_id], boxes[sorted_indices[1:]])\n",
    "        \n",
    "        # Remove boxes with IoU over the threshold\n",
    "        keep_indices = np.where(ious < threshold)[0]\n",
    "        \n",
    "        # Update the indices\n",
    "        sorted_indices = sorted_indices[keep_indices + 1]\n",
    "    print(\"Keep boxes: \", keep_boxes)\n",
    "    return keep_boxes\n",
    "\n",
    "def calculate_iou(box, boxes):\n",
    "    # Calculate intersection areas\n",
    "    x1 = np.maximum(box[0], boxes[:, 0])\n",
    "    y1 = np.maximum(box[1], boxes[:, 1])\n",
    "    x2 = np.minimum(box[2], boxes[:, 2])\n",
    "    y2 = np.minimum(box[3], boxes[:, 3])\n",
    "    \n",
    "    intersection_area = np.maximum(0, x2 - x1) * np.maximum(0, y2 - y1)\n",
    "    \n",
    "    # Calculate union areas\n",
    "    box_area = (box[2] - box[0]) * (box[3] - box[1])\n",
    "    boxes_area = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])\n",
    "    union_area = box_area + boxes_area - intersection_area\n",
    "    \n",
    "    # Calculate IoU\n",
    "    iou = intersection_area / union_area\n",
    "    return iou\n",
    "\n",
    "def template_matching(image, template, threshold):\n",
    "    result = cv2.matchTemplate(image, template, cv2.TM_CCOEFF_NORMED)\n",
    "    #plot_image(result)\n",
    "    locations = np.where(result >= threshold)\n",
    "    scores = result[locations]\n",
    "    matches = list(zip(*locations[::-1]))\n",
    "    \n",
    "    return matches, scores\n",
    "\n",
    "def average_perimeter_intensity(image, center, radius):\n",
    "    # Create a circular mask\n",
    "    mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "    cv2.circle(mask, center, radius, 255, 1)\n",
    "    \n",
    "    # Extract perimeter pixels\n",
    "    perimeter_pixels = image[mask == 255]\n",
    "    \n",
    "    # Calculate average intensity\n",
    "    average_intensity = np.mean(perimeter_pixels)\n",
    "    \n",
    "    return average_intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f4703f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform template matching\n",
    "matches,scores = template_matching(image, template, matching_threshold)\n",
    "\n",
    "#print(\"Scores:\", scores)\n",
    "#print(\"Match locations: \", matches)\n",
    "\n",
    "\n",
    "# Create bounding boxes\n",
    "w, h = template.shape[::-1]\n",
    "boxes = [(x, y, x + w, y + h) for (x, y) in matches]\n",
    "#print(\"Boxes: \", boxes)\n",
    "\n",
    "# Apply non-maximum suppression for filtering out overlapping boxes\n",
    "keep_ids = non_max_suppression(np.array(boxes), scores, overlap_threshold)\n",
    "\n",
    "#print(\"Kept_boxes: \", np.array(keep_ids))\n",
    "#print(matches[keep_ids[0]])\n",
    "\n",
    "# Do not filter out the matches\n",
    "#loc = [matches[keep_id] for keep_id in keep_ids]\n",
    "\n",
    "# Filter out the matches with average perimeter intensity over 110\n",
    "loc = [matches[keep_id] for keep_id in keep_ids if average_perimeter_intensity(image, matches[keep_id], 6) < 110]\n",
    "\n",
    "\n",
    "# Draw rectangles around the matched regions\n",
    "img2 = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "for pt in loc:\n",
    "    cv2.rectangle(img2, pt, (pt[0] + w, pt[1] + h), (0, 255, 0), 2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568e7c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save FP position saved in loc variable in a Pandas dataframe with columns: 'id', 'name', 'pos_x', 'pos_y'\n",
    "\n",
    "target_df = list_to_dataframe(loc) #str(output_folder/\"target_df.csv\")\n",
    "print(target_df)\n",
    "\n",
    "# Convert dataframe into numpy array of coordinate pairs (X,Y), XML file and PLY file\n",
    "#target = dataframe_to_nparray(target_df)\n",
    "#dataframe_to_xml(target_df)       # str(output_folder/\"target.xml\")\n",
    "target_pcd = dataframe_to_pointcloud(target_df, str(output_folder/\"target-test.ply\"))  # \"str(output_folder/target.ply)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0e4d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plot_image(img2)\n",
    "plt.savefig('fiducial_detection.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162153a1",
   "metadata": {},
   "source": [
    "### Filtering of the detected fiducial particles \n",
    "\n",
    "Clusters of fiducial particles (FP) will be replaced by 1 point located in the centre of the cluster. Single FP will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba5eab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a black image of the same size as img2, then draw filled circles with the radius of FP at the locations \n",
    "# of FP taken from the loc variable, dilate the binary image by circular kernel to connect nearby FP, save the image\n",
    "\n",
    "img_mask = np.zeros_like(img2)\n",
    "for pt in loc:\n",
    "    # draw a filled circle around the fiducial particle\n",
    "    cv2.circle(img_mask, (pt[0] + w//2, pt[1] + h//2), fiducial_diam//2, (255, 255, 255), -1)\n",
    "    # draw a filled rectangle around the fiducial particle\n",
    "    #cv2.rectangle(img_mask, pt, (pt[0] + w, pt[1] + h), (255, 255, 255), -1)\n",
    "\n",
    "# Dilate img_mask by circluar kernel of size 7x7\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))\n",
    "img_mask = cv2.dilate(img_mask, kernel, iterations=1)\n",
    "\n",
    "plot_image(img_mask)\n",
    "plt.savefig('fiducial_detection_mask.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bb204e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate for each connected component the centroid and the pixel area, if the area is larger then \n",
    "# the area of 3 fiducial particles then keep the FP, save the centroid and the area into a list\n",
    "\n",
    "# Find connected components\n",
    "_, labels = cv2.connectedComponents(img_mask)\n",
    "\n",
    "# Calculate the centroid and area of each connected component\n",
    "centroids = []\n",
    "areas = []\n",
    "\n",
    "for label in np.unique(labels):\n",
    "    if label == 0:             # skip the background\n",
    "        continue\n",
    "    \n",
    "    mask = np.zeros_like(img_mask, dtype=np.uint8)\n",
    "    mask[labels == label] = 1\n",
    "    \n",
    "    moments = cv2.moments(mask)\n",
    "    print(\"Moments: \", moments)\n",
    "\n",
    "    if moments[\"m00\"] > 1500:   # 2 * fiducial_diam * fiducial_diam:\n",
    "        centroids.append((int(moments[\"m10\"] / moments[\"m00\"]), int(moments[\"m01\"] / moments[\"m00\"])))\n",
    "        areas.append(int(moments[\"m00\"]))\n",
    "        #print(moment[\"m00\"])\n",
    "\n",
    "print(\"Centroids: \", centroids)\n",
    "print(\"Areas: \", areas)\n",
    "\n",
    "# Draw the centroids on the original image\n",
    "img3 = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "for centroid in centroids:\n",
    "    cv2.circle(img3, centroid, 5, (0, 255, 0), -1)\n",
    "\n",
    "plot_image(img3)\n",
    "plt.savefig('fiducial_detection_centroids.png')\n",
    "\n",
    "# Save the centroids and areas into a text file\n",
    "output_path = Path('filtered_fiducial_detection.txt')\n",
    "with open(output_path, 'w') as f:\n",
    "    for centroid, area in zip(centroids, areas):\n",
    "        f.write(f\"{centroid[0]},{centroid[1]},{area}\\n\")\n",
    "\n",
    "print(\"Output saved to: \", output_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b3faf6",
   "metadata": {},
   "source": [
    "Save the FP locations and filtered FP locations into a pandas dataframe and then point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cffbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save FP position saved in centroids variable into a Pandas dataframe with columns: 'id', 'name', 'pos_x', 'pos_y'\n",
    "\n",
    "target_s_df = list_to_dataframe(centroids) #str(output_folder/\"target_s_df.csv\")\n",
    "print(target_s_df)\n",
    "\n",
    "# Convert dataframe into numpy array of coordinate pairs (X,Y), XML file and PLY file\n",
    "#target_s = dataframe_to_nparray(target_s_df)\n",
    "#dataframe_to_xml(target_s_df)       # str(output_folder/\"target.xml\")\n",
    "target_s_pcd = dataframe_to_pointcloud(target_s_df, str(output_folder/\"target-s-test.ply\"))  # \"target.ply\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI4Life_OC2_2024_26",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
