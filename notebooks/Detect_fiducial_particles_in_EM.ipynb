{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40e2ea0d",
   "metadata": {},
   "source": [
    "# Detecting the fiducial particles in EM images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08507027",
   "metadata": {},
   "source": [
    "Fiducial particles/markers are used in correlated light and electron microscopy (CLEM) to enable accurate overlaying of fluorescence (LM) and electron microscopy (EM) images. The fiducial particles in EM images appear as bright circular regions with dark central spot. \n",
    "\n",
    "In this notebook, we **detect fiducial particles** in **EM images** using the template matching algorithm. As a template we use an artificially generated bright image with dark spot in the middle that resembles with its appearence the central part of the fiducial particle. After matching this template to the individual fiducial particles we detect fiducial clusters that consists of at least three fiducial particles in close proximity of each other. The main steps of this algorithm are:\n",
    "- **1. Fiducial particle detection** - Detection of fiducial particles using the template matching algorithm.\n",
    "- **2. Cluster detection** - Filtering the set of individual fiducial particles by recognizing clusters of touching fiducial particles and replacing these clusters by their centroid positions.\n",
    "- **3. Results saving** - Saving the positions of all detected fiducial particles and the positions of fiducial clusters into files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91991e39",
   "metadata": {},
   "source": [
    "Load the necessary python libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc93023",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage import exposure\n",
    "import matplotlib.pyplot as plt\n",
    "#from imutils.object_detection import non_max_suppression\n",
    "from utils_template_matching import non_max_suppression, template_matching, normalize_image, filter_the_template_matching_results\n",
    "from utils import plot_image, list_to_dataframe, dataframe_to_csv, dataframe_to_xml, dataframe_to_pointcloud, dataframe_to_xml_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaba3ab",
   "metadata": {},
   "source": [
    "Set the path to the input EM image and values for the parameters, load the EM image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c83a584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the imput EM image and template\n",
    "input_folder = 'E:/DATA/AI4Life_Pr26/20240805_Trial_data_fiducial_particles/240723_JB294_CLEM-AI4life_sample1/pos1'\n",
    "image_path = Path(os.path.join(input_folder, \"240726_JB295_HEK293_CLEM_LAMP1-488_Particles-555_grid4_pos1_bin4_EM.tif\"))\n",
    "print(image_path.exists())\n",
    "\n",
    "output_folder = Path(os.path.join(input_folder,\"output\"))\n",
    "output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "test_folder = Path('//vironova.com/root/Users/kristinal/Documents/1Test')\n",
    "\n",
    "image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Parameters for template generation    #Sample1/bin 2 needs size 11, otherwise size 9 works fine\n",
    "template_size = 9     # Create an empty template of size ('size','size') filled with constant value - 'value' 9, 11\n",
    "template_value = 80    # 80, 90\n",
    "\n",
    "# Parameters for template matching\n",
    "matching_threshold = 0.7  # threshold for template matching\n",
    "overlap_threshold = 0.1\n",
    "\n",
    "# Get template dimensions\n",
    "# h, w = template.shape\n",
    "\n",
    "# Information about fiducial particles\n",
    "fiducial_diam = 27     # diameter of fiducial particles in px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08855bd",
   "metadata": {},
   "source": [
    "## 1. Fiducial particle detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe27593",
   "metadata": {},
   "source": [
    "### Creating a template for the template matching\n",
    "\n",
    "Fiducial particles have a very distinct central region, characterized by a dark spot surrounded by a lighter gray region. Instead of attempting to match the entire particle using a full template, we focus on detecting the central region only. To accomplish this, the template can be easily generated artificially. We create an initial example template of size (9,9). This example template will be immediately resized to the desired template size which was set up earlier using parameter 'template_size'.\n",
    "\n",
    "Using a full particle template did not work satisfactory because of the variaty of the region around the particle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f35a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the template as an empty template of size ('size','size') filled with constant value - 'value'\n",
    "example_template = np.full((9, 9), template_value, dtype=np.uint8)\n",
    "\n",
    "# Define the 3x3 pattern\n",
    "template_pattern = np.array([[4, 2, 4],\n",
    "                             [2, 0, 2],\n",
    "                             [4, 2, 4]])\n",
    "\n",
    "# Calculate the starting index to place the pattern in the middle of the template\n",
    "s_idx = (example_template.shape[0] - template_pattern.shape[0]) // 2\n",
    "e_idx = s_idx + template_pattern.shape[0]\n",
    "    \n",
    "# Place the pattern in the middle of the template\n",
    "example_template[s_idx:e_idx, s_idx:e_idx] = template_pattern\n",
    "\n",
    "#import bigfish.stack as stack\n",
    "#template = stack.resize_image(template,(template.shape[0]*2,template.shape[0]*2), method='bilinear')\n",
    "\n",
    "example_template = example_template.astype(np.uint8)\n",
    "template = cv2.resize(example_template, (template_size,template_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4d94ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image(template,(10))\n",
    "print(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7532633e",
   "metadata": {},
   "source": [
    "Template matching is performed. The matches are first filtered so we ensure that the matches are unique and not overlapping. Then we filter false positives by looking at the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f4703f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform template matching\n",
    "matching_threshold = 0.7 # 0.68\n",
    "\n",
    "matches, scores = template_matching(normalize_image(image), template, matching_threshold)\n",
    "print('Matches:', len(matches), matches)\n",
    "\n",
    "# Create bounding boxes\n",
    "w, h = template.shape[::-1]\n",
    "boxes = [(x, y, x + w, y + h) for (x, y) in matches]    # x,y is the probably the middle of the box, but it does not matter \n",
    "                                                        # when calculating the box overlap\n",
    "# Apply non-maximum suppression for filtering out overlapping boxes\n",
    "keep_ids = non_max_suppression(np.array(boxes), scores, overlap_threshold)\n",
    "\n",
    "# Center the matches\n",
    "loc = [np.asarray(matches[keep_id])+[w//2,h//2] for keep_id in keep_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15b5408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the template matching results based on average intensity\n",
    "loc1, loc2, loc3 = filter_the_template_matching_results(loc, normalize_image(image), 1, 6, 3) # size of middle square, size of outer square, size of inner square for ring\n",
    "\n",
    "# Draw rectangles around the matched regions\n",
    "img2 = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "#for pt in loc1:\n",
    "#    cv2.circle(img2, (pt[0] + w , pt[1] + h ), 1, (0, 128, 0), 2)\n",
    "      \n",
    "#for pt in loc2:\n",
    "#    cv2.circle(img2, (pt[0] - w , pt[1] - h ), 1, (255, 255, 0), 2)\n",
    "\n",
    "for pt in loc3:\n",
    "    cv2.rectangle(img2, (pt[0] - fiducial_diam//2 , pt[1] - fiducial_diam//2 ), (pt[0] + fiducial_diam//2 , pt[1] + fiducial_diam//2), (0, 0, 0), 2)\n",
    "    \n",
    "# Correct locations are the ones that are in loc3 after filtering\n",
    "loc = loc3\n",
    "\n",
    "cv2.imwrite(str(output_folder/'fiducial_detection.png'), img2)\n",
    "plot_image(img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162153a1",
   "metadata": {},
   "source": [
    "### 2. Cluster detection\n",
    "\n",
    "Clusters of fiducial particles (FP) will be detected and replaced by 1 point located in the centre of the cluster. Single FP will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba5eab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a black image of the same size as img2, then draw filled circles with the radius of FP at the locations \n",
    "# of FP taken from the loc variable, dilate the binary image by circular kernel to connect nearby FP, save the image\n",
    "\n",
    "img_mask = np.zeros_like(img2)\n",
    "for pt in loc:\n",
    "    # draw a filled circle around the fiducial particle\n",
    "    cv2.circle(img_mask, pt, fiducial_diam//2, (255, 255, 255), -1)\n",
    "    \n",
    "# Dilate img_mask by circluar kernel of size 7x7\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))\n",
    "img_mask = cv2.dilate(img_mask, kernel, iterations=1)\n",
    "\n",
    "plot_image(img_mask)\n",
    "plt.savefig(str(output_folder/'fiducial_detection_mask.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bb204e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate for each connected component the centroid and the pixel area, if the area is larger then \n",
    "# the area of 3 fiducial particles then keep the FP, save the centroid and the area into a list\n",
    "\n",
    "# Find connected components\n",
    "_, labels = cv2.connectedComponents(img_mask)\n",
    "\n",
    "# Calculate the centroid and area of each connected component\n",
    "centroids = []\n",
    "areas = []\n",
    "\n",
    "for label in np.unique(labels):\n",
    "    if label == 0:             # skip the background\n",
    "        continue\n",
    "    \n",
    "    mask = np.zeros_like(img_mask, dtype=np.uint8)\n",
    "    mask[labels == label] = 1\n",
    "    \n",
    "    moments = cv2.moments(mask)\n",
    "    #print(\"Moments: \", moments)\n",
    "\n",
    "    if moments[\"m00\"] > (3 * math.pi * (fiducial_diam//2)**2) :   # equivalent to the area of 3 fiducial particles\n",
    "        centroids.append((int(moments[\"m10\"] / moments[\"m00\"]), int(moments[\"m01\"] / moments[\"m00\"])))\n",
    "        areas.append(int(moments[\"m00\"]))\n",
    "        #print(moment[\"m00\"])\n",
    "\n",
    "print(\"Centroids: \", centroids)\n",
    "print(\"Areas: \", areas)\n",
    "\n",
    "# Draw the centroids on the original image\n",
    "img3 = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "for centroid in centroids:\n",
    "    cv2.circle(img3, centroid, 5, (0, 255, 0), -1)\n",
    "\n",
    "cv2.imwrite(str(output_folder/'fiducial_detection_centroids.png'), img3)\n",
    "plot_image(img3)\n",
    "\n",
    "clusters = centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b3faf6",
   "metadata": {},
   "source": [
    "### 3. Results saving\n",
    "\n",
    "Save the FP locations and filtered FP locations into a pandas dataframe with columns: 'id', 'name', 'pos_x', 'pos_y'. Then convert dataframe into numpy array of coordinate pairs (X,Y), XML file and PLY file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5059c254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all detected fiducial particles into a Pandas dataframe and export it to different file formats\n",
    "def save_spots_to_diffent_files (spots, folder, file_name, scale):    \n",
    "    spots_df = list_to_dataframe(spots, os.path.join(folder, f\"{file_name}_df.csv\"))                                                     #str(output_folder/\"source_all_df.csv\")\n",
    "\n",
    "    dataframe_to_xml(spots_df, os.path.join(folder, f\"{file_name}.xml\"))                      # import file for ICY ec-CLEM plugin\n",
    "    dataframe_to_xml(spots_df, os.path.join(folder, f\"{file_name}_scaled.xml\"), scale)                      # import file for ICY ec-CLEM plugin\n",
    "    dataframe_to_pointcloud(spots_df, os.path.join(folder, f\"{file_name}.ply\"))                      # import file for point cloud registration using Probgreg package in Python\n",
    "    dataframe_to_csv(spots_df, os.path.join(folder, f\"{file_name}.csv\"))                             # import file for BigWarp ImageJ plugin\n",
    "    return spots_df\n",
    "\n",
    "#df = save_spots_to_diffent_files(np.unique((spots_post_decomposition), axis=0), output_folder, \"source_all\", [scale_y, scale_x])  # y and x are swapped in the dataframe\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbeede3",
   "metadata": {},
   "source": [
    "Save the fiducial particles and detected clusters locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8250a193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the detected spots 'spots' as representants for regions\n",
    "scale_x = 1\n",
    "scale_y = 1\n",
    "loc_swapped = [(x, y) for y, x in loc]\n",
    "clusters_swapped = [(x, y) for y, x in clusters]\n",
    "\n",
    "df = save_spots_to_diffent_files(np.unique((loc_swapped), axis=0), output_folder, \"target_all\", [scale_y, scale_x])  # y and x are swapped in the dataframe\n",
    "print(df)\n",
    "\n",
    "# Save the 'clusters'\n",
    "df = save_spots_to_diffent_files(np.unique((clusters_swapped), axis=0), output_folder, \"target_clusters\", [scale_y, scale_x])  # y and x are swapped in the dataframe\n",
    "print(df) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI4Life_OC2_2024_26",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
