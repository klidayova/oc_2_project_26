{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2bd973a",
   "metadata": {},
   "source": [
    "This notebook aims to test different registration methods using the Ground Truth points that were manually detected on EM and LM images.\n",
    "\n",
    "#### Loading the Ground truth files in XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "70880430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import bigfish.stack as stack\n",
    "import bigfish.plot as plot\n",
    "from utils import xml_to_dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cd189a",
   "metadata": {},
   "source": [
    "Load the locations for fiducial particles in EM and LM. The locations were manually detected using ICY software and were saved in XML format. These point locations are considered to be the ground truth. For further processing we need to load the XML format and convert it into Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514f3a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_xml = 'Ground_truth_fiducials_EM.xml'\n",
    "target_df = xml_to_dataframe(target_xml)\n",
    "print(target_df)\n",
    "\n",
    "source_xml = 'Ground_truth_fiducials_LM.xml'\n",
    "source_df_small = xml_to_dataframe(source_xml)\n",
    "print(source_df_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9364d2b",
   "metadata": {},
   "source": [
    "EM and LM images have most probably different sizes. LM image is usually much smaller. The points that were detected in LM image coordinate system needs to be rescaled to EM image coordinate system, otherwise it might be very hard with the registration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fdee3f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_the_scale(EM_shape, LM_shape):\n",
    "    scale_x = EM_shape[0]/LM_shape[0]\n",
    "    scale_y = EM_shape[1]/LM_shape[1]\n",
    "    return scale_x, scale_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52a1d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the EM and LM images\n",
    "\n",
    "input_path = \"E:/DATA/AI4Life_Pr26/20240805_Trial_data_fiducial_particles/240723_JB294_CLEM-AI4life_sample1/pos1\"\n",
    "\n",
    "EM_image_path = os.path.join(input_path, \"240726_JB295_HEK293_CLEM_LAMP1-488_Particles-555_grid4_pos1_bin4_EM.tif\")\n",
    "LM_image_path  = os.path.join(input_path, \"240726_JB295_HEK293_CLEM_LAMP1-488_Particles-555_grid4_pos1_LM.tif\")\n",
    "\n",
    "EMimage = stack.read_image(EM_image_path)\n",
    "LMimage_small = stack.read_image(LM_image_path)\n",
    "\n",
    "\n",
    "# Find what is the scaling rate between the 2 images\n",
    "scale_x, scale_y = find_the_scale(EMimage.shape, LMimage_small.shape)\n",
    "\n",
    "print(\"Scale x: \",scale_x)\n",
    "print(\"Scale y: \",scale_y)\n",
    "\n",
    "\n",
    "# Resize the LM point positions\n",
    "source_df = xml_to_dataframe(source_xml)\n",
    "source_df['pos_x'] = source_df_small['pos_x']*scale_x\n",
    "source_df['pos_y'] = source_df_small['pos_y']*scale_y\n",
    "\n",
    "\n",
    "# Resize the LM image to fit the position of the resized points\n",
    "LMimage = stack.resize_image(LMimage_small, EMimage.shape, method='bilinear')\n",
    "\n",
    "#scale_x = 24.873456790123456\n",
    "#scale_y = 22.966165413533833"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58466bb",
   "metadata": {},
   "source": [
    "Converting the Panda dataframe into numpy array (2D points (X,Y) and 3D points (X,Y,Z)). The 3D points are needed if we plan to convert them to point clouds later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3aec0e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting dataframe into numpy array of coordinate pairs (X,Y) \n",
    "target = target_df[['pos_x', 'pos_y']].to_numpy()\n",
    "source = source_df[['pos_x', 'pos_y']].to_numpy()\n",
    "source_small = source_df_small[['pos_x', 'pos_y']].to_numpy()\n",
    "\n",
    "# Adding the Z-dimension to the 2D points\n",
    "target3D = np.hstack((target, np.zeros((len(target), 1))))\n",
    "source3D = np.hstack((source, np.zeros((len(source), 1))))\n",
    "source3D_small = np.hstack((source_small, np.zeros((len(source_small), 1))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI4Life_OC2_2024_26",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
